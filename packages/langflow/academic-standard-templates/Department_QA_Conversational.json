{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-qQ80Y",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "PerplexityDirectModel-QzFB2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-qQ80Y{œdataTypeœ:œPromptœ,œidœ:œPrompt-qQ80Yœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityDirectModel-QzFB2{œfieldNameœ:œsystem_messageœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-qQ80Y",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-qQ80Yœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityDirectModel-QzFB2",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PerplexityDirectModel",
            "id": "PerplexityDirectModel-QzFB2",
            "name": "message_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-SWced",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PerplexityDirectModel-QzFB2{œdataTypeœ:œPerplexityDirectModelœ,œidœ:œPerplexityDirectModel-QzFB2œ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-SWced{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SWcedœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PerplexityDirectModel-QzFB2",
        "sourceHandle": "{œdataTypeœ:œPerplexityDirectModelœ,œidœ:œPerplexityDirectModel-QzFB2œ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-SWced",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SWcedœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-bH4Ty",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-yyqRZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-bH4Ty{œdataTypeœ:œChatInputœ,œidœ:œChatInput-bH4Tyœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-yyqRZ{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-yyqRZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-bH4Ty",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-bH4Tyœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-yyqRZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-yyqRZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-yyqRZ",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_message",
            "id": "PerplexityDirectModel-QzFB2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-yyqRZ{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-yyqRZœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-PerplexityDirectModel-QzFB2{œfieldNameœ:œinput_messageœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-yyqRZ",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-yyqRZœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityDirectModel-QzFB2",
        "targetHandle": "{œfieldNameœ:œinput_messageœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-WUmX8",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "department_name",
            "id": "Prompt-Zmmn4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-WUmX8{œdataTypeœ:œTextInputœ,œidœ:œTextInput-WUmX8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Zmmn4{œfieldNameœ:œdepartment_nameœ,œidœ:œPrompt-Zmmn4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-WUmX8",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-WUmX8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-Zmmn4",
        "targetHandle": "{œfieldNameœ:œdepartment_nameœ,œidœ:œPrompt-Zmmn4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-WUmX8",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "department_name",
            "id": "Prompt-qQ80Y",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-WUmX8{œdataTypeœ:œTextInputœ,œidœ:œTextInput-WUmX8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-qQ80Y{œfieldNameœ:œdepartment_nameœ,œidœ:œPrompt-qQ80Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-WUmX8",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-WUmX8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-qQ80Y",
        "targetHandle": "{œfieldNameœ:œdepartment_nameœ,œidœ:œPrompt-qQ80Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-Zmmn4",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-yyqRZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-Zmmn4{œdataTypeœ:œPromptœ,œidœ:œPrompt-Zmmn4œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-yyqRZ{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-yyqRZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-Zmmn4",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Zmmn4œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-yyqRZ",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-yyqRZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-Ea8jy",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "department_url",
            "id": "Prompt-qQ80Y",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-Ea8jy{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Ea8jyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-qQ80Y{œfieldNameœ:œdepartment_urlœ,œidœ:œPrompt-qQ80Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-Ea8jy",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Ea8jyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-qQ80Y",
        "targetHandle": "{œfieldNameœ:œdepartment_urlœ,œidœ:œPrompt-qQ80Yœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-Ea8jy",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_domain_filter",
            "id": "PerplexityDirectModel-QzFB2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-Ea8jy{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Ea8jyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-PerplexityDirectModel-QzFB2{œfieldNameœ:œsearch_domain_filterœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-Ea8jy",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-Ea8jyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityDirectModel-QzFB2",
        "targetHandle": "{œfieldNameœ:œsearch_domain_filterœ,œidœ:œPerplexityDirectModel-QzFB2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatOutput-SWced",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "outputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-SWced",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 1703.3776946668427,
          "y": 855.50890912733
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-qQ80Y",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "department_name",
                "department_url"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "department_name": {
                "advanced": false,
                "display_name": "department_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "department_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "Hariri Institute for Computing"
              },
              "department_url": {
                "advanced": false,
                "display_name": "department_url",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "department_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "https://www.bu.edu/hic"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a helpful assistant for visitors to the {department_name} website at Boston University that is found at {department_url}.\n\nPlease provide concise answers in a friendly and welcoming tone to queries from the context of {department_name} only. Always provide hyperlinks so that users may learn more if they want.\n\nIf the query is obviously about anything other than {department_name} at Boston University, politely inform them that you are unable to help."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-qQ80Y",
        "measured": {
          "height": 495,
          "width": 320
        },
        "position": {
          "x": 712.6168981037363,
          "y": 520.129478599017
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PerplexityDirectModel-QzFB2",
          "node": {
            "base_classes": [
              "Message",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Perplexity API with citations and source domain filtering.",
            "display_name": "Perplexity Direct API",
            "documentation": "https://docs.perplexity.ai/",
            "edited": true,
            "field_order": [
              "input_message",
              "system_message",
              "model_name",
              "api_key",
              "search_domain_filter",
              "search_recency_filter",
              "max_tokens",
              "temperature",
              "top_p",
              "top_k",
              "presence_penalty",
              "frequency_penalty",
              "return_citations",
              "format_citations_as_links",
              "return_related_questions",
              "return_images"
            ],
            "frozen": false,
            "icon": "Perplexity",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Text Output",
                "hidden": null,
                "method": "get_text_output",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Output",
                "hidden": false,
                "method": "get_message_output",
                "name": "message_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Perplexity API Key",
                "dynamic": false,
                "info": "Your Perplexity API Key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport httpx\nfrom typing import Any, Dict, List, Optional, Union\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Text\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput, MessageTextInput, Output, MessageInput\nfrom langflow.schema.message import Message\nfrom langflow.schema import Data\nimport re\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity Direct API\"\n    description = \"Generate text using Perplexity API with citations and source domain filtering.\"\n    documentation = \"https://docs.perplexity.ai/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityDirectModel\"\n    \n    inputs = [\n        MessageInput(\n            name=\"input_message\",\n            display_name=\"Input\",\n            info=\"The message or question to send to Perplexity\",\n            required=False,  # Made optional so it can receive from connections\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System instructions to guide the model's behavior\",\n            advanced=False,  # Make it visible by default\n            value=\"You are a helpful assistant. Always provide accurate information and cite your sources.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"sonar\",\n                \"sonar-pro\", \n                \"sonar-reasoning\",\n            ],\n            value=\"sonar\",\n            info=\"Sonar models include web search and return citations\"\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"Your Perplexity API Key\",\n            advanced=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"search_domain_filter\",\n            display_name=\"Search Domain Filter\",\n            info=\"Comma-separated domains to include or exclude. Use '-' prefix to exclude (e.g., 'wikipedia.org, arxiv.org, -reddit.com')\",\n            advanced=False,\n            value=\"\",\n        ),\n        DropdownInput(\n            name=\"search_recency_filter\",\n            display_name=\"Search Recency Filter\",\n            info=\"Filter search results by time period\",\n            advanced=False,\n            options=[\n                \"\",  # No filter\n                \"hour\",\n                \"day\", \n                \"week\",\n                \"month\",\n                \"year\",\n            ],\n            value=\"\",\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"Maximum number of tokens to generate\",\n            advanced=True,\n            value=1024,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.1),\n            info=\"Controls randomness in generation\"\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"Nucleus sampling parameter\",\n            advanced=True,\n            value=0.9,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Top-k sampling parameter (0 to disable)\",\n            advanced=True,\n            value=0,  # Default to 0 (disabled)\n        ),\n        FloatInput(\n            name=\"presence_penalty\",\n            display_name=\"Presence Penalty\",\n            info=\"Penalizes new tokens based on whether they appear in the text so far\",\n            advanced=True,\n            value=0.0,\n            range_spec=RangeSpec(min=-2, max=2, step=0.1),\n        ),\n        FloatInput(\n            name=\"frequency_penalty\",\n            display_name=\"Frequency Penalty\",\n            info=\"Penalizes new tokens based on their frequency in the text so far\",\n            advanced=True,\n            value=0.0,\n            range_spec=RangeSpec(min=-2, max=2, step=0.1),\n        ),\n        BoolInput(\n            name=\"return_citations\",\n            display_name=\"Return Citations\",\n            info=\"Include citations in the response (enabled by default for sonar models)\",\n            value=True,\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"format_citations_as_links\",\n            display_name=\"Format Citations as Links\",\n            info=\"Format citations as clickable markdown links\",\n            value=True,\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"return_related_questions\",\n            display_name=\"Return Related Questions\",\n            info=\"Include related follow-up questions in the response\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"return_images\",\n            display_name=\"Return Images\",\n            info=\"Include images in search results (when available)\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n    \n    outputs = [\n        Output(\n            display_name=\"Text Output\",\n            name=\"text_output\",\n            method=\"get_text_output\"\n        ),\n        Output(\n            display_name=\"Chat Output\",\n            name=\"message_output\", \n            method=\"get_message_output\"\n        ),\n    ]\n    \n    def parse_domain_filter(self) -> List[str]:\n        \"\"\"Parse the domain filter string into a list for the API.\"\"\"\n        if not self.search_domain_filter:\n            return []\n            \n        # Split by comma and clean up each entry\n        domains = []\n        for domain in self.search_domain_filter.split(','):\n            domain = domain.strip()\n            if domain:\n                # Remove common prefixes that shouldn't be there\n                # But preserve the '-' prefix for exclusions\n                if domain.startswith('-'):\n                    # Exclusion - keep the minus and clean the domain part\n                    clean_domain = domain[1:].replace('https://', '').replace('http://', '').replace('www.', '').strip()\n                    domains.append(f\"-{clean_domain}\")\n                else:\n                    # Inclusion - just clean the domain\n                    clean_domain = domain.replace('https://', '').replace('http://', '').replace('www.', '').strip()\n                    domains.append(clean_domain)\n                    \n        return domains\n    \n    def call_perplexity_api(self, messages: List[Dict], **kwargs) -> Dict:\n        \"\"\"Make a direct API call to Perplexity.\"\"\"\n        api_key = self.api_key\n        \n        # Prepare the API request\n        headers = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n        \n        # Build request payload with proper type conversion\n        payload = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"return_citations\": bool(self.return_citations),\n            \"return_related_questions\": bool(self.return_related_questions),\n            \"return_images\": bool(self.return_images),\n        }\n        \n        # Add search domain filter if specified\n        domain_filter = self.parse_domain_filter()\n        if domain_filter:\n            payload[\"search_domain_filter\"] = domain_filter\n            print(f\"DEBUG: Applying domain filter: {domain_filter}\")\n            \n        # Add search recency filter if specified\n        if self.search_recency_filter and self.search_recency_filter != \"\":\n            payload[\"search_recency_filter\"] = self.search_recency_filter\n            print(f\"DEBUG: Applying recency filter: {self.search_recency_filter}\")\n        \n        # Add numeric parameters with proper type conversion\n        # Temperature\n        if self.temperature is not None:\n            try:\n                payload[\"temperature\"] = float(self.temperature)\n            except (ValueError, TypeError):\n                payload[\"temperature\"] = 0.7  # Default\n                \n        # Top P\n        if self.top_p is not None:\n            try:\n                payload[\"top_p\"] = float(self.top_p)\n            except (ValueError, TypeError):\n                payload[\"top_p\"] = 0.9  # Default\n                \n        # Max tokens\n        if self.max_tokens is not None:\n            try:\n                payload[\"max_tokens\"] = int(self.max_tokens)\n            except (ValueError, TypeError):\n                payload[\"max_tokens\"] = 1024  # Default\n                \n        # Frequency penalty\n        if self.frequency_penalty is not None:\n            try:\n                payload[\"frequency_penalty\"] = float(self.frequency_penalty)\n            except (ValueError, TypeError):\n                payload[\"frequency_penalty\"] = 0.0  # Default\n                \n        # Presence penalty\n        if self.presence_penalty is not None:\n            try:\n                payload[\"presence_penalty\"] = float(self.presence_penalty)\n            except (ValueError, TypeError):\n                payload[\"presence_penalty\"] = 0.0  # Default\n        \n        # Add top_k only if specified and valid (not all models support it)\n        if self.top_k is not None:\n            try:\n                top_k_value = int(self.top_k)\n                if top_k_value > 0:\n                    payload[\"top_k\"] = top_k_value\n            except (ValueError, TypeError):\n                pass  # Skip if can't convert\n            \n        # Remove None values and empty strings\n        payload = {k: v for k, v in payload.items() if v is not None and v != \"\"}\n        \n        # Debug: Print the final payload (can be commented out in production)\n        print(f\"DEBUG: Sending payload to Perplexity API: {json.dumps(payload, indent=2)}\")\n        \n        try:\n            # Make the API request\n            with httpx.Client() as client:\n                response = client.post(\n                    \"https://api.perplexity.ai/chat/completions\",\n                    headers=headers,\n                    json=payload,\n                    timeout=60.0\n                )\n                response.raise_for_status()\n                result = response.json()\n                \n                # Debug: Print citations if present\n                if 'citations' in result:\n                    print(f\"DEBUG: Found {len(result['citations'])} citations in API response\")\n                    \n                return result\n        except httpx.HTTPError as e:\n            error_msg = f\"Perplexity API error: {str(e)}\"\n            if hasattr(e, 'response') and hasattr(e.response, 'text'):\n                error_msg += f\" - Response: {e.response.text}\"\n            raise ValueError(error_msg)\n        except Exception as e:\n            raise ValueError(f\"Error calling Perplexity API: {str(e)}\")\n    \n    def format_citations_as_markdown(self, content: str, citations: List[Any]) -> str:\n        \"\"\"Format citations as clickable markdown links with page titles.\"\"\"\n        if not citations or not self.format_citations_as_links:\n            return content\n            \n        # Check if content already has citation markers like [1], [2], etc.\n        has_markers = bool(re.findall(r'\\[\\d+\\]', content))\n        \n        formatted_content = content\n        \n        # Add a sources section\n        formatted_content += \"\\n\\n### 📚 Sources\\n\"\n        \n        # Add note about domain filtering if filter was applied\n        if self.search_domain_filter:\n            domain_filter = self.parse_domain_filter()\n            included = [d for d in domain_filter if not d.startswith('-')]\n            excluded = [d[1:] for d in domain_filter if d.startswith('-')]\n            \n            if included:\n                formatted_content += f\"*Searched only: {', '.join(included)}*\\n\"\n            if excluded:\n                formatted_content += f\"*Excluded: {', '.join(excluded)}*\\n\"\n            formatted_content += \"\\n\"\n        \n        for i, citation in enumerate(citations, 1):\n            # Try to extract title and URL from citation\n            url = None\n            title = None\n            \n            if isinstance(citation, dict):\n                # If citation is a dict, look for url and title fields\n                url = citation.get('url', '') or citation.get('link', '')\n                title = citation.get('title', '') or citation.get('name', '') or citation.get('snippet', '')\n            elif isinstance(citation, str):\n                # If citation is just a URL string\n                url = citation\n                \n            # If we have a URL but no title, try to extract a title from the URL\n            if url and not title:\n                # Try to extract a meaningful title from the URL\n                # Remove protocol and www\n                clean_url = url.replace('https://', '').replace('http://', '').replace('www.', '')\n                \n                # Try to get the page name from the path\n                if '/' in clean_url:\n                    parts = clean_url.split('/')\n                    # Get domain\n                    domain = parts[0]\n                    # Get last meaningful part of path\n                    path_parts = [p for p in parts[1:] if p and not p.startswith('?')]\n                    \n                    if path_parts:\n                        # Special handling for common sites\n                        if 'wikipedia.org' in domain:\n                            # For Wikipedia, use the article name\n                            if 'wiki/' in url:\n                                title = path_parts[-1].replace('_', ' ')\n                            else:\n                                title = f\"Wikipedia: {path_parts[-1].replace('_', ' ')}\"\n                        elif 'arxiv.org' in domain:\n                            # For arXiv, show paper ID\n                            title = f\"arXiv: {path_parts[-1]}\"\n                        elif 'github.com' in domain:\n                            # For GitHub, show repo name\n                            if len(path_parts) >= 2:\n                                title = f\"GitHub: {path_parts[0]}/{path_parts[1]}\"\n                            else:\n                                title = f\"GitHub: {path_parts[0]}\"\n                        elif 'stackoverflow.com' in domain:\n                            # For StackOverflow, try to get question title\n                            title = \"StackOverflow: \" + (path_parts[-1] if path_parts else \"Question\")\n                        else:\n                            # For other sites, use the last path segment\n                            last_part = path_parts[-1]\n                            # Clean up common file extensions\n                            last_part = last_part.replace('.html', '').replace('.php', '').replace('.aspx', '')\n                            # Replace hyphens and underscores with spaces\n                            last_part = last_part.replace('-', ' ').replace('_', ' ')\n                            # Capitalize words\n                            title = ' '.join(word.capitalize() for word in last_part.split())\n                    else:\n                        # If no path, use domain\n                        title = domain.split('.')[0].capitalize()\n                else:\n                    # Just domain, no path\n                    title = clean_url.split('.')[0].capitalize()\n                    \n            # Final fallback if still no title\n            if not title:\n                title = f\"Source {i}\"\n                \n            # Format the citation\n            if url:\n                # Clean up title if it's too long\n                if len(title) > 100:\n                    title = title[:97] + \"...\"\n                    \n                # Format based on whether we have numbered references in text\n                if has_markers:\n                    formatted_content += f\"[{i}] [{title}]({url})\\n\"\n                else:\n                    formatted_content += f\"• [{title}]({url})\\n\"\n            else:\n                # No URL, just show the title or text\n                if has_markers:\n                    formatted_content += f\"[{i}] {title or citation}\\n\"\n                else:\n                    formatted_content += f\"• {title or citation}\\n\"\n                        \n        return formatted_content\n    \n    def format_related_questions(self, related_questions: List[str]) -> str:\n        \"\"\"Format related questions as a nice section.\"\"\"\n        if not related_questions:\n            return \"\"\n            \n        formatted = \"\\n\\n### 💡 Related Questions\\n\"\n        for question in related_questions:\n            formatted += f\"• {question}\\n\"\n        return formatted\n    \n    def format_images(self, images: List[Dict]) -> str:\n        \"\"\"Format images if included in the response.\"\"\"\n        if not images:\n            return \"\"\n            \n        formatted = \"\\n\\n### 🖼️ Related Images\\n\"\n        for img in images:\n            if isinstance(img, dict):\n                url = img.get('url', '')\n                caption = img.get('caption', '') or img.get('alt', '')\n                if url:\n                    if caption:\n                        formatted += f\"• ![{caption}]({url})\\n\"\n                    else:\n                        formatted += f\"• ![Image]({url})\\n\"\n        return formatted\n    \n    def process_message(self, input_value: Any) -> Message:\n        \"\"\"Process the input and generate a response with citations.\"\"\"\n        # Extract the actual message text\n        user_message = \"\"\n        \n        if isinstance(input_value, Message):\n            user_message = input_value.text\n        elif isinstance(input_value, dict):\n            user_message = input_value.get('text', '') or input_value.get('content', '') or str(input_value)\n        elif isinstance(input_value, str):\n            user_message = input_value\n        elif hasattr(input_value, 'text'):\n            user_message = input_value.text\n        elif input_value is not None:\n            user_message = str(input_value)\n            \n        # If still no message, check if input_message has a value\n        if not user_message and hasattr(self, 'input_message'):\n            if isinstance(self.input_message, Message):\n                user_message = self.input_message.text\n            elif isinstance(self.input_message, str):\n                user_message = self.input_message\n            elif self.input_message:\n                user_message = str(self.input_message)\n        \n        if not user_message:\n            raise ValueError(\"No input message provided\")\n            \n        # Build messages array for API\n        messages = []\n        \n        # Add system message if provided\n        if self.system_message:\n            messages.append({\n                \"role\": \"system\",\n                \"content\": self.system_message\n            })\n            \n        # Add user message\n        messages.append({\n            \"role\": \"user\",\n            \"content\": user_message\n        })\n        \n        # Call Perplexity API\n        api_response = self.call_perplexity_api(messages)\n        \n        # Extract the response content\n        if 'choices' in api_response and len(api_response['choices']) > 0:\n            choice = api_response['choices'][0]\n            content = choice.get('message', {}).get('content', '')\n            \n            # Extract citations if present\n            citations = api_response.get('citations', [])\n            \n            # Extract images if present\n            images = api_response.get('images', [])\n            \n            # Format citations as markdown links if enabled\n            if citations and self.format_citations_as_links:\n                content = self.format_citations_as_markdown(content, citations)\n                \n            # Add images if present\n            if images and self.return_images:\n                content += self.format_images(images)\n                \n            # Add related questions if enabled and present\n            if self.return_related_questions:\n                related_questions = api_response.get('related_questions', [])\n                if related_questions:\n                    content += self.format_related_questions(related_questions)\n            \n            # Create the Message object with metadata\n            message = Message(\n                text=content,\n                sender_name=\"Perplexity\",\n                metadata={\n                    \"model\": self.model_name,\n                    \"citations\": citations,\n                    \"domain_filter\": self.parse_domain_filter(),\n                    \"recency_filter\": self.search_recency_filter,\n                    \"images\": images,\n                    \"usage\": api_response.get('usage', {}),\n                    \"id\": api_response.get('id', ''),\n                    \"related_questions\": api_response.get('related_questions', [])\n                }\n            )\n            \n            # Store for output methods\n            self.last_message = message\n            \n            return message\n        else:\n            raise ValueError(\"No response from Perplexity API\")\n    \n    def build_model(self) -> Any:\n        \"\"\"Build model is required by LCModelComponent but we'll handle the API call directly.\"\"\"\n        # Return self as we're handling the API calls directly\n        return self\n    \n    def run_model(self, *args, **kwargs) -> Message:\n        \"\"\"Main execution method that processes input and returns response.\"\"\"\n        # Extract input from various possible sources\n        input_value = None\n        \n        # Check args\n        if args:\n            input_value = args[0]\n        # Check kwargs\n        elif 'input' in kwargs:\n            input_value = kwargs['input']\n        elif 'message' in kwargs:\n            input_value = kwargs['message']\n        elif 'input_message' in kwargs:\n            input_value = kwargs['input_message']\n        # Check instance attribute\n        elif hasattr(self, 'input_message') and self.input_message:\n            input_value = self.input_message\n            \n        if input_value is None:\n            raise ValueError(\"No input provided to process\")\n            \n        return self.process_message(input_value)\n    \n    def get_message_output(self) -> Message:\n        \"\"\"Return the message for the Chat Output.\"\"\"\n        if hasattr(self, 'last_message'):\n            return self.last_message\n        \n        # If no stored message, run the model\n        if hasattr(self, 'input_message') and self.input_message:\n            return self.run_model(self.input_message)\n        else:\n            # Return empty message if no input\n            return Message(text=\"No input provided\", sender_name=\"Perplexity\")\n    \n    def get_text_output(self) -> str:\n        \"\"\"Return just the text for the Text Output.\"\"\"\n        message = self.get_message_output()\n        return message.text\n    \n    def invoke(self, input: Union[str, Message, Dict], config: Optional[Dict] = None) -> Message:\n        \"\"\"Process input and return response with formatted citations.\"\"\"\n        return self.process_message(input)\n    \n    async def ainvoke(self, input: Union[str, Message, Dict], config: Optional[Dict] = None) -> Message:\n        \"\"\"Async version of invoke.\"\"\"\n        # For now, just call the sync version\n        # You could make this truly async with httpx.AsyncClient if needed\n        return self.invoke(input, config)"
              },
              "format_citations_as_links": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Format Citations as Links",
                "dynamic": false,
                "info": "Format citations as clickable markdown links",
                "list": false,
                "list_add_label": "Add More",
                "name": "format_citations_as_links",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "frequency_penalty": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Frequency Penalty",
                "dynamic": false,
                "info": "Penalizes new tokens based on their frequency in the text so far",
                "list": false,
                "list_add_label": "Add More",
                "name": "frequency_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": -2,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "input_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The message or question to send to Perplexity",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "Maximum number of tokens to generate",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1024
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Sonar models include web search and return citations",
                "name": "model_name",
                "options": [
                  "sonar",
                  "sonar-pro",
                  "sonar-reasoning"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "sonar"
              },
              "presence_penalty": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Presence Penalty",
                "dynamic": false,
                "info": "Penalizes new tokens based on whether they appear in the text so far",
                "list": false,
                "list_add_label": "Add More",
                "name": "presence_penalty",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": -2,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "return_citations": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Return Citations",
                "dynamic": false,
                "info": "Include citations in the response (enabled by default for sonar models)",
                "list": false,
                "list_add_label": "Add More",
                "name": "return_citations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "return_images": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Return Images",
                "dynamic": false,
                "info": "Include images in search results (when available)",
                "list": false,
                "list_add_label": "Add More",
                "name": "return_images",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "return_related_questions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Return Related Questions",
                "dynamic": false,
                "info": "Include related follow-up questions in the response",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "return_related_questions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "search_domain_filter": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Domain Filter",
                "dynamic": false,
                "info": "Comma-separated domains to include or exclude. Use '-' prefix to exclude (e.g., 'wikipedia.org, arxiv.org, -reddit.com')",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_domain_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_recency_filter": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Recency Filter",
                "dynamic": false,
                "info": "Filter search results by time period",
                "name": "search_recency_filter",
                "options": [
                  "",
                  "hour",
                  "day",
                  "week",
                  "month",
                  "year"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System instructions to guide the model's behavior",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in generation",
                "load_from_db": false,
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 1
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Top-k sampling parameter (0 to disable)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "Nucleus sampling parameter",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PerplexityDirectModel"
        },
        "id": "PerplexityDirectModel-QzFB2",
        "measured": {
          "height": 883,
          "width": 320
        },
        "position": {
          "x": 1221.5308848077136,
          "y": 381
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-yyqRZ",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4.1-nano"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Your job is to transform user queries that visitors to the {institute_name} make so that they are grammatically correct and relevant to {institute_name}.\nFor example:\nQuery: whos the director\nResponse: Who is the director of the {institute_name} at Boston University?\n\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-yyqRZ",
        "measured": {
          "height": 614,
          "width": 320
        },
        "position": {
          "x": 695.818943895798,
          "y": -142.53269666937888
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-bH4Ty",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000045030081906763545,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-bH4Ty",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": -44.51451601882942,
          "y": 152.6636282081575
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-Zmmn4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "department_name"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "department_name": {
                "advanced": false,
                "display_name": "department_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "department_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Your job is to transform user queries that visitors to the {department_name} make so that they are grammatically correct and relevant to {department_name}.\nFor example:\nQuery: whos the director\nResponse: Who is the director of the {department_name} at Boston University?\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-Zmmn4",
        "measured": {
          "height": 412,
          "width": 320
        },
        "position": {
          "x": 258.68984381178666,
          "y": 239.22616391957604
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-WUmX8",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get text inputs from the Playground.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Hariri Institute for Computing"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-WUmX8",
        "measured": {
          "height": 230,
          "width": 320
        },
        "position": {
          "x": -117.7192464098964,
          "y": 766.1173786386471
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-kTS3S",
          "node": {
            "description": "Add Ddepartment Name on top left text input prompt\n\n\nAdd department url to top right",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-kTS3S",
        "measured": {
          "height": 324,
          "width": 325
        },
        "position": {
          "x": 99.19179128065929,
          "y": 1042.9404388784476
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "TextInput-Ea8jy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get text inputs from the Playground.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://www.bu.edu/hic"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-Ea8jy",
        "measured": {
          "height": 230,
          "width": 320
        },
        "position": {
          "x": 280.89571810446637,
          "y": 765.625712091742
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -0.9262603512925125,
      "y": -464.40829075317015,
      "zoom": 0.8612671705494601
    }
  },
  "description": "QA template to answer questions embedded on sites.",
  "endpoint_name": null,
  "id": "ee0b31a4-6c10-48b2-add1-06df89d82eb6",
  "is_component": false,
  "last_tested_version": "1.4.1",
  "name": "Perplexity QA",
  "tags": []
}