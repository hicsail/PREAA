// This file is auto-generated by @hey-api/openapi-ts

export type CreateLangFlowMapping = {
    /**
     * The model name
     */
    model: string;
    /**
     * The URL of the Langflow mapping
     */
    url: string;
    /**
     * The history component ID
     */
    historyComponentID: string;
};

export type LangFlowMapping = {
    /**
     * Unique identifier
     */
    _id: string;
    /**
     * Model name
     */
    model: string;
    /**
     * URL to the Langflow instance
     */
    url: string;
    /**
     * Creation timestamp
     */
    createdAt: string;
    /**
     * Last update timestamp
     */
    updatedAt: string;
};

export type UpdateLangFlowMapping = {
    /**
     * New model name
     */
    model: string;
    /**
     * New url
     */
    url: string;
    /**
     * New history component
     */
    historyComponentID: string;
};

export type ObjectId = {
    [key: string]: unknown;
};

export type DeepchatProxy = {
    /**
     * MongoDB generated id
     */
    _id: ObjectId;
    /**
     * The model the deepchat proxy should talk to
     */
    model: string;
    /**
     * The LiteLLM url to communicate against
     */
    url: string;
};

export type CreateProxyMappingDto = {
    /**
     * The model identifier used for LLM requests
     */
    model: string;
    /**
     * Base URL for the API service
     */
    url: string;
    /**
     * API key for authentication with the LLM provider
     */
    apiKey: string;
};

export type Message = {
    /**
     * Role of the message sender
     */
    role: 'system' | 'user' | 'assistant';
    /**
     * Content of the message
     */
    text: string;
};

export type ProxyCompletion = {
    /**
     * Array of messages in the conversation
     */
    messages: Array<Message>;
    /**
     * Maximum number of tokens to generate
     */
    max_tokens?: number;
    /**
     * Sampling temperature (0-2)
     */
    temperature?: number;
};

export type Usage = {
    /**
     * Tokens needed to make completion
     */
    completion_tokens: number;
    /**
     * Tokens used by prompt
     */
    prompt_tokens: number;
    /**
     * Total tokens used in interaction
     */
    total_tokens: number;
    /**
     * Additional context on completion token usagage
     */
    completion_tokens_details: {
        [key: string]: unknown;
    };
    /**
     * Additional context on prompt token usage
     */
    prompt_tokens_details: {
        [key: string]: unknown;
    };
};

export type CompletionResponse = {
    /**
     * The id of the completion
     */
    id: string;
    /**
     * Creation date
     */
    created: number;
    /**
     * Model that make the completion
     */
    model: string;
    object: string;
    choices: Array<string>;
    /**
     * Usage information
     */
    usage: Usage;
    text: string;
};

export type CreateNewModelParams = {
    /**
     * Model name for the backend
     */
    model: string;
    /**
     * Base URL for the model
     */
    api_base: string;
    /**
     * API key needed to be passed to the model backend
     */
    api_key: string;
    /**
     * The name of the custom provider (if needed)
     */
    custom_llm_provider: string;
};

export type CreateNewModel = {
    /**
     * The name of the model
     */
    model_name: string;
    /**
     * LiteLLM parameters for configuring the model
     */
    litellm_params: CreateNewModelParams;
};

export type LangflowMappingControllerGetAllData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/mapping';
};

export type LangflowMappingControllerGetAllErrors = {
    /**
     * Server error
     */
    500: unknown;
};

export type LangflowMappingControllerGetAllResponses = {
    /**
     * List of all mappings with their configurations
     */
    200: Array<LangFlowMapping>;
};

export type LangflowMappingControllerGetAllResponse = LangflowMappingControllerGetAllResponses[keyof LangflowMappingControllerGetAllResponses];

export type LangflowMappingControllerCreateData = {
    body: CreateLangFlowMapping;
    path?: never;
    query?: never;
    url: '/mapping';
};

export type LangflowMappingControllerCreateErrors = {
    /**
     * Invalid input data
     */
    400: unknown;
};

export type LangflowMappingControllerCreateResponses = {
    /**
     * The mapping has been successfully created
     */
    201: LangFlowMapping;
};

export type LangflowMappingControllerCreateResponse = LangflowMappingControllerCreateResponses[keyof LangflowMappingControllerCreateResponses];

export type LangflowMappingControllerUpdateData = {
    /**
     * Updated mapping data
     */
    body: UpdateLangFlowMapping;
    path?: never;
    query?: never;
    url: '/mapping';
};

export type LangflowMappingControllerUpdateErrors = {
    /**
     * Mapping not found
     */
    404: unknown;
};

export type LangflowMappingControllerUpdateResponses = {
    /**
     * The mapping has been successfully updated
     */
    200: LangFlowMapping;
};

export type LangflowMappingControllerUpdateResponse = LangflowMappingControllerUpdateResponses[keyof LangflowMappingControllerUpdateResponses];

export type LangflowMappingControllerDeleteData = {
    body?: never;
    path: {
        /**
         * Model identifier to delete
         */
        model: string;
    };
    query?: never;
    url: '/mapping/{model}';
};

export type LangflowMappingControllerDeleteErrors = {
    /**
     * Mapping not found
     */
    404: unknown;
};

export type LangflowMappingControllerDeleteResponses = {
    /**
     * The mapping has been successfully deleted
     */
    200: unknown;
};

export type LangflowMappingControllerGetData = {
    body?: never;
    path: {
        /**
         * Model identifier
         */
        model: string;
    };
    query?: never;
    url: '/mapping/{model}';
};

export type LangflowMappingControllerGetErrors = {
    /**
     * Mapping not found
     */
    404: unknown;
};

export type LangflowMappingControllerGetResponses = {
    /**
     * The mapping has been found
     */
    200: LangFlowMapping;
};

export type LangflowMappingControllerGetResponse = LangflowMappingControllerGetResponses[keyof LangflowMappingControllerGetResponses];

export type DeepchatProxyControllerGetData = {
    body?: never;
    path: {
        /**
         * MongoDB ObjectId of the proxy record
         */
        id: string;
    };
    query?: never;
    url: '/deepchat-proxy/{id}';
};

export type DeepchatProxyControllerGetErrors = {
    /**
     * Proxy not found
     */
    404: unknown;
};

export type DeepchatProxyControllerGetResponses = {
    /**
     * The proxy has been found
     */
    200: DeepchatProxy;
};

export type DeepchatProxyControllerGetResponse = DeepchatProxyControllerGetResponses[keyof DeepchatProxyControllerGetResponses];

export type DeepchatProxyControllerUpdateData = {
    body: CreateProxyMappingDto;
    path: {
        /**
         * MongoDB ObjectId of the proxy to update
         */
        id: string;
    };
    query?: never;
    url: '/deepchat-proxy/{id}';
};

export type DeepchatProxyControllerUpdateErrors = {
    /**
     * Proxy not found
     */
    404: unknown;
};

export type DeepchatProxyControllerUpdateResponses = {
    /**
     * The proxy has been successfully updated
     */
    200: DeepchatProxy;
};

export type DeepchatProxyControllerUpdateResponse = DeepchatProxyControllerUpdateResponses[keyof DeepchatProxyControllerUpdateResponses];

export type DeepchatProxyControllerGetAllData = {
    body?: never;
    path?: never;
    query?: never;
    url: '/deepchat-proxy';
};

export type DeepchatProxyControllerGetAllResponses = {
    /**
     * List of all proxies
     */
    200: Array<DeepchatProxy>;
};

export type DeepchatProxyControllerGetAllResponse = DeepchatProxyControllerGetAllResponses[keyof DeepchatProxyControllerGetAllResponses];

export type DeepchatProxyControllerCreateData = {
    body: CreateProxyMappingDto;
    path?: never;
    query?: never;
    url: '/deepchat-proxy';
};

export type DeepchatProxyControllerCreateErrors = {
    /**
     * Invalid input data or model already exists
     */
    400: unknown;
};

export type DeepchatProxyControllerCreateResponses = {
    /**
     * The proxy has been successfully created
     */
    201: DeepchatProxy;
};

export type DeepchatProxyControllerCreateResponse = DeepchatProxyControllerCreateResponses[keyof DeepchatProxyControllerCreateResponses];

export type DeepchatProxyControllerDeleteData = {
    body?: never;
    path: {
        /**
         * Model name to delete
         */
        model: string;
    };
    query?: never;
    url: '/deepchat-proxy/{model}';
};

export type DeepchatProxyControllerDeleteErrors = {
    /**
     * Proxy not found
     */
    404: unknown;
};

export type DeepchatProxyControllerDeleteResponses = {
    /**
     * The proxy has been successfully deleted
     */
    200: unknown;
};

export type DeepchatProxyControllerProxyRequestData = {
    body: ProxyCompletion;
    path: {
        /**
         * Proxy identifier (MongoDB ObjectId)
         */
        id: string;
    };
    query?: never;
    url: '/deepchat-proxy/proxy/{id}';
};

export type DeepchatProxyControllerProxyRequestErrors = {
    /**
     * Proxy not found
     */
    404: unknown;
    /**
     * Error communicating with the LLM provider
     */
    500: unknown;
};

export type DeepchatProxyControllerProxyRequestResponses = {
    /**
     * Successful completion response
     */
    200: CompletionResponse;
};

export type DeepchatProxyControllerProxyRequestResponse = DeepchatProxyControllerProxyRequestResponses[keyof DeepchatProxyControllerProxyRequestResponses];

export type LiteLlmControllerCreateData = {
    body: CreateNewModel;
    path?: never;
    query?: never;
    url: '/litellm';
};

export type LiteLlmControllerCreateResponses = {
    201: unknown;
};

export type ClientOptions = {
    baseUrl: string;
};